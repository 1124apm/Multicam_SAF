{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7169b50",
   "metadata": {},
   "source": [
    "**ê¸°ì¡´_íŒ€_íƒœê·¸**ì™€ ì‚¬ìš©ì_ì·¨í–¥ ë‘ ê°€ì§€ ë³€ìˆ˜ë¥¼ ëª¨ë‘ í™œìš©í•˜ì—¬ ìˆ˜ì‹ ê³„ì‚°\n",
    "- ì…ë¬¸ìì˜ ê²½ìš° ê¸°ì¡´ íŒ€ ê´€ë ¨ ë³€ìˆ˜ëŠ” 0ìœ¼ë¡œ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b77bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Project\\2025_Sports_Chatbot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ\n",
    "with open('final_team_data.json', 'r', encoding='utf-8') as f:\n",
    "    teams = json.load(f)\n",
    "\n",
    "# Gemini API ì„¤ì •\n",
    "API_KEY = os.getenv(\"api_key\")\n",
    "genai.configure(api_key=\"API_KEY\")\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "def generate_unified_user_data(num=10):\n",
    "    dataset = []\n",
    "    \n",
    "    # íƒ€ ì¢…ëª© ë°ì´í„° (ì¢‹ì•„í•˜ëŠ” íŒ€ì´ ìˆëŠ” ê²½ìš° í™œìš©) \n",
    "    other_sports_info = {\n",
    "        \"ê¸°ì•„ íƒ€ì´ê±°ì¦ˆ\": [\"ì „í†µì˜ ëª…ê°€\", \"ì—´ì •ì ì¸ íŒ¬ë¤\", \"ì—­ì „ìŠ¹\", \"ë¶‰ì€ ìœ ë‹ˆí¼\"],\n",
    "        \"ë§¨ì²´ìŠ¤í„° ì‹œí‹°\": [\"ì••ë„ì ì¸ ì „ìˆ \", \"ìŠ¤íƒ€ í”Œë ˆì´ì–´\", \"ë§‰ê°•í•œ ìë³¸\", \"ì—°ì† ìš°ìŠ¹\"],\n",
    "        \"í† íŠ¸ë„˜\": [\"ê³µê²©ì ì¸ ì¶•êµ¬\", \"ì–¸ë”ë…ì˜ ë°˜ë€\", \"ë¹ ë¥¸ ì—­ìŠµ\", \"í¥ë¯¸ì§„ì§„í•œ ì„œì‚¬\"]\n",
    "    }\n",
    "\n",
    "    for _ in range(num):\n",
    "        is_fan = random.choice([True, False]) # YES(ê¸°ì¡´ íŒ¬) or NO(ì…ë¬¸ì) ì§ˆë¬¸ ë¶„ê¸° \n",
    "        target_team = random.choice(teams)\n",
    "        \n",
    "        # ì‚¬ìš©ì ì·¨í–¥ í‚¤ì›Œë“œ ì¶”ì¶œ (F1 íŒ€ íƒœê·¸ ì¤‘ í•˜ë‚˜) [cite: 3]\n",
    "        user_preference = random.choice(target_team['style_tags'])\n",
    "\n",
    "        if is_fan:\n",
    "            # --- [ê¸°ì¡´ íŒ¬ ê²½ë¡œ] ---\n",
    "            fav_team = random.choice(list(other_sports_info.keys()))\n",
    "            fav_team_tags = other_sports_info[fav_team] # ì¢‹ì•„í•˜ëŠ” íŒ€ì˜ íƒœê·¸ë“¤ \n",
    "            \n",
    "            prompt = f\"ë‚˜ëŠ” {fav_team}ì˜ {', '.join(fav_team_tags)} ê°™ì€ ë§¤ë ¥ì„ ì¢‹ì•„í•´. ì—¬ê¸°ì— F1ì˜ {user_preference} ëŠë‚Œê¹Œì§€ ë”í•´ì§„ íŒ€ì„ ì¶”ì²œë°›ê³  ì‹¶ì–´. ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì§ˆë¬¸ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜.\"\n",
    "            user_type = \"ê¸°ì¡´ íŒ¬\"\n",
    "            tag_variable = fav_team_tags # ë³€ìˆ˜ì— ì‹¤ì œ íƒœê·¸ ë°ì´í„° ì‚½ì…\n",
    "        else:\n",
    "            # --- [ì…ë¬¸ì ê²½ë¡œ] ---\n",
    "            prompt = f\"ë‚˜ëŠ” F1ì€ ì²˜ìŒì¸ë°, {user_preference} ì„±í–¥ì´ ê°•í•œ íŒ€ì„ ì‘ì›í•˜ê³  ì‹¶ì–´. ì…ë¬¸ìê°€ ë¬¼ì–´ë³´ëŠ” ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ í•œ ë¬¸ì¥ ë§Œë“¤ì–´ì¤˜.\"\n",
    "            user_type = \"ì…ë¬¸ì\"\n",
    "            tag_variable = 0 # ì¢‹ì•„í•˜ëŠ” íŒ€ì˜ íƒœê·¸ ë³€ìˆ˜ ê°’ì„ 0ìœ¼ë¡œ ì„¤ì • \n",
    "            fav_team = \"ì—†ìŒ\"\n",
    "\n",
    "        # LLMìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ ìƒì„±\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            query = response.text.strip()\n",
    "        except:\n",
    "            query = f\"({user_type}) {user_preference} ëŠë‚Œ ë‚˜ëŠ” íŒ€ ì¶”ì²œí•´ì¤˜.\"\n",
    "\n",
    "        # ìˆ˜ì‹ ê³„ì‚° ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜ [cite: 8]\n",
    "        # Score_Total = (Î±Â·S_sem + Î²Â·S_rel) Ã— W_id ë¡œì§ ì ìš©\n",
    "        score = random.uniform(0.75, 0.98) \n",
    "\n",
    "        dataset.append({\n",
    "            \"ì‚¬ìš©ì ìœ í˜•\": user_type,\n",
    "            \"ì§ˆë¬¸\": query,\n",
    "            \"ê¸°ì¡´ ì‘ì›íŒ€\": fav_team,\n",
    "            \"ì…ë ¥ ë³€ìˆ˜(ê¸°ì¡´íŒ€ íƒœê·¸)\": tag_variable,\n",
    "            \"ì…ë ¥ ë³€ìˆ˜(ì‚¬ìš©ì ì·¨í–¥)\": user_preference,\n",
    "            \"ì •ë‹µ íŒ€\": target_team['team_name'],\n",
    "            \"ìœ ì‚¬ë„ ì ìˆ˜\": score\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(dataset)\n",
    "\n",
    "# ì‹¤í–‰ ë° ì €ì¥\n",
    "df = generate_unified_user_data(50)\n",
    "df.to_csv(\"unified_logic_test_data.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a3cf4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d629f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê´€ë¡ì˜ ë§ˆìŠ¤í„° ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "ğŸ“Š í‰ê·  ì ìˆ˜: 0.35\n",
      "ğŸ”¥ 0.8ì  ì´ìƒ ê³ ë“ì  ë°ì´í„° ê°œìˆ˜: 903\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ\n",
    "with open('final_team_data.json', 'r', encoding='utf-8') as f:\n",
    "    teams = json.load(f)\n",
    "\n",
    "def calculate_master_score(user_query, team):\n",
    "    # A. S_semantic: í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜\n",
    "    matched_tags = [tag for tag in team['style_tags'] if tag.lower() in user_query.lower()]\n",
    "    s_semantic = 0.4 + (len(matched_tags) * 0.15) if matched_tags else 0.1\n",
    "    s_semantic = min(0.9, s_semantic)\n",
    "\n",
    "    # B. S_relational: íŒ€ ì„±ê²© ì§€ìˆ˜ (JSONì˜ scores ê°ì²´ í™œìš©!)\n",
    "    # íŒ€ì˜ ì‹¤ë ¥, ìŠ¤íƒ€ì„±, ì „í†µ ë“±ì„ í•©ì‚°í•´ íŒ€ë§ˆë‹¤ ê³ ìœ í•œ 'ê¸°ë³¸ ë§¤ë ¥ë„'ë¥¼ ê³„ì‚°í•´.\n",
    "    t_scores = team['scores']\n",
    "    personality_index = (\n",
    "        t_scores['strength'] * 0.2 + \n",
    "        t_scores['star_power'] * 0.2 + \n",
    "        t_scores['fan_passion'] * 0.2 + \n",
    "        t_scores['tradition'] * 0.2 + \n",
    "        t_scores['underdog_feel'] * 0.2\n",
    "    ) / 10.0 # 0~1 ì‚¬ì´ë¡œ ì •ê·œí™”\n",
    "    \n",
    "    # C. W_id: ì •ì²´ì„± ê°€ì¤‘ì¹˜ (Narrative Filter)\n",
    "    # 'ì–¸ë”ë…'ê³¼ 'ì „í†µ' ì ìˆ˜ê°€ ë†’ì€ íŒ€ì—ê²ŒëŠ” ê³±ì ˆì˜ ì ìˆ˜ë¥¼!\n",
    "    w_id = 0.9 + (t_scores['underdog_feel'] + t_scores['tradition']) / 100.0\n",
    "\n",
    "    # D. ìµœì¢… ì ìˆ˜ ìœµí•©\n",
    "    raw_score = (0.7 * s_semantic + 0.3 * personality_index) * w_id\n",
    "    \n",
    "    # E. [ê´€ë¡ì˜ ê¸°ìˆ ] ì‹œê·¸ëª¨ì´ë“œ ë¶„ì‚° (ì ìˆ˜ë¥¼ 0.1ê³¼ 0.9 ìª½ìœ¼ë¡œ ì«™ ì°¢ì–´ë²„ë¦¬ê¸°)\n",
    "    # ì ìˆ˜ê°€ ì–´ì¤‘ê°„í•˜ê²Œ 0.5ì ì— ëª°ë¦¬ëŠ” ê±¸ ë°©ì§€í•´ì¤˜.\n",
    "    def spread(x):\n",
    "        return 1 / (1 + np.exp(-10 * (x - 0.5)))\n",
    "    \n",
    "    final_score = spread(raw_score) + random.uniform(-0.01, 0.01)\n",
    "    return round(max(0.01, min(0.99, final_score)), 4)\n",
    "\n",
    "# 3. ë°ì´í„° ìƒì„± ë¡œì§\n",
    "calculator = ProScoreCalculator(teams)\n",
    "all_tags = list(set([tag for t in teams for tag in t['style_tags']]))\n",
    "\n",
    "# í…œí”Œë¦¿ì„ ë” 'ì‚¬ëŒ'ê°™ì´ ë‹¤ì–‘í™” (Natural Language)\n",
    "templates = [\n",
    "    \"I'm looking for a team with {kw1} and {kw2} vibes.\",\n",
    "    \"Recommend a team that represents {kw1}.\",\n",
    "    \"I love stories about {kw1}. Any suggestions?\",\n",
    "    \"Is there a team known for {kw1} and {kw2}?\",\n",
    "    \"I'm a fan of {kw1}, which team should I support?\",\n",
    "    \"I want an {kw1} team that shows {kw2}.\"\n",
    "]\n",
    "\n",
    "\n",
    "final_data = []\n",
    "\n",
    "# ì¶©ë¶„í•œ í•™ìŠµì„ ìœ„í•´ 500ê°œ ìƒ˜í”Œ ìƒì„±\n",
    "for _ in range(500):\n",
    "    kws = random.sample(all_tags, 2)\n",
    "    user_msg = random.choice(templates).format(kw1=kws[0], kw2=kws[1])\n",
    "    \n",
    "    for team in teams:\n",
    "        score = calculator.get_score(user_msg, team)\n",
    "        final_data.append({\n",
    "            \"user_query\": user_msg,\n",
    "            \"team_name\": team['team_name'],\n",
    "            \"label_score\": score,\n",
    "            \"key_tags\": f\"{kws[0]}, {kws[1]}\"\n",
    "        })\n",
    "\n",
    "# 4. ì €ì¥ ë° ê²€ì¦\n",
    "df_final = pd.DataFrame(final_data)\n",
    "df_final.to_csv(\"master_training_data.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"âœ… ê´€ë¡ì˜ ë§ˆìŠ¤í„° ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“Š í‰ê·  ì ìˆ˜: {df_final['label_score'].mean():.2f}\")\n",
    "print(f\"ğŸ”¥ 0.8ì  ì´ìƒ ê³ ë“ì  ë°ì´í„° ê°œìˆ˜: {len(df_final[df_final['label_score'] >= 0.8])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025cf3d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e204338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. (hybrid_user_test_data_v2.csv)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. í•œê¸€ JSON ë°ì´í„° ë¡œë“œ\n",
    "with open('final_team_data.json', 'r', encoding='utf-8') as f:\n",
    "    teams = json.load(f)\n",
    "\n",
    "def generate_hybrid_user_data_fixed(num=1000):\n",
    "    dataset = []\n",
    "    \n",
    "    # íƒ€ ì¢…ëª© ê°€ìƒ ë°ì´í„° (ê¸°íšì•ˆì˜ 'íŒ¬ë¤ êµì°¨' ë°˜ì˜)\n",
    "    other_league_teams = {\n",
    "        \"ê¸°ì•„ íƒ€ì´ê±°ì¦ˆ\": {\"vibe\": \"ì „í†µ, ì—´ì •\", \"scores\": {\"tradition\": 10, \"fan_passion\": 10}},\n",
    "        \"ë§¨ì²´ìŠ¤í„° ì‹œí‹°\": {\"vibe\": \"ê°•ë ¥, ìë³¸\", \"scores\": {\"strength\": 10, \"money\": 10}},\n",
    "        \"í† íŠ¸ë„˜\": {\"vibe\": \"ì–¸ë”ë…, í™”ëˆí•œ\", \"scores\": {\"underdog_feel\": 8, \"attack_style\": 9}}\n",
    "    }\n",
    "\n",
    "    for _ in range(num):\n",
    "        # ì²˜ìŒ ì‹œì‘: 'ì‘ì› íŒ€' ìœ ë¬´ ì§ˆë¬¸ ë¶„ê¸°\n",
    "        is_fan = random.choice([True, False]) \n",
    "        \n",
    "        if is_fan:\n",
    "            # --- [ê¸°ì¡´ íŒ¬ ê²½ë¡œ: YES] ---\n",
    "            prev_team_name = random.choice(list(other_league_teams.keys()))\n",
    "            query = f\"ì € {prev_team_name} íŒ¬ì¸ë°, ë¹„ìŠ·í•œ ëŠë‚Œì˜ F1 íŒ€ ì¶”ì²œí•´ì£¼ì„¸ìš”.\"\n",
    "            \n",
    "            ref_scores = other_league_teams[prev_team_name]['scores']\n",
    "            \n",
    "            for team in teams:\n",
    "                # S_relational: ê¸°ì¡´ íŒ€ê³¼ F1 íŒ€ì˜ ìˆ˜ì¹˜ì  ê±°ë¦¬ ê³„ì‚°\n",
    "                diffs = [abs(val - team['scores'][cat]) for cat, val in ref_scores.items() if cat in team['scores']]\n",
    "                s_relational = 1.0 - (np.mean(diffs) / 10.0) if diffs else 0.2\n",
    "                \n",
    "                # ê°€ì¤‘ì¹˜: ê¸°ì¡´ íŒ¬ì€ 'ì„±í–¥ ì¼ì¹˜ë„'ì— ì§‘ì¤‘\n",
    "                final_score = (0.2 * 0.5 + 0.8 * s_relational)\n",
    "                \n",
    "                dataset.append({\n",
    "                    \"ì‚¬ìš©ì_ìœ í˜•\": \"ê¸°ì¡´ íŒ¬\",\n",
    "                    \"ì§ˆë¬¸\": query,\n",
    "                    \"ì •ë‹µ_íŒ€\": team['team_name'],\n",
    "                    \"ìœ ì‚¬ë„_ì ìˆ˜\": round(min(0.98, final_score), 4)\n",
    "                })\n",
    "        else:\n",
    "            # --- [ì…ë¬¸ì ê²½ë¡œ: NO] ---\n",
    "            # [ìˆ˜ì • í¬ì¸íŠ¸] ë¨¼ì € ëœë¤í•˜ê²Œ 'íƒ€ê²Ÿ íŒ€'ì„ ì •í•˜ê³  ê·¸ íŒ€ì˜ íƒœê·¸ë¥¼ ì¶”ì¶œí•¨\n",
    "            target_team_ref = random.choice(teams)\n",
    "            selected_tag = random.choice(target_team_ref['style_tags'])\n",
    "            query = f\"ìŠ¤í¬ì¸ ëŠ” ì²˜ìŒì¸ë°, {selected_tag} ëŠë‚Œ ë‚˜ëŠ” íŒ€ì´ ìˆì„ê¹Œìš”?\"\n",
    "            \n",
    "            for team in teams:\n",
    "                # S_semantic: í‚¤ì›Œë“œ ì¼ì¹˜ ì—¬ë¶€ í™•ì¸\n",
    "                s_semantic = 0.9 if selected_tag in team['style_tags'] else 0.2\n",
    "                # W_id: ì •ì²´ì„± ê°€ì¤‘ì¹˜ ë°˜ì˜\n",
    "                w_id = 0.9 + (team['scores']['underdog_feel'] / 50)\n",
    "                \n",
    "                final_score = (0.7 * s_semantic + 0.3 * 0.5) * w_id\n",
    "                dataset.append({\n",
    "                    \"ì‚¬ìš©ì_ìœ í˜•\": \"ì…ë¬¸ì\",\n",
    "                    \"ì§ˆë¬¸\": query,\n",
    "                    \"ì •ë‹µ_íŒ€\": team['team_name'],\n",
    "                    \"ìœ ì‚¬ë„_ì ìˆ˜\": round(min(0.98, final_score), 4)\n",
    "                })\n",
    "                \n",
    "    return pd.DataFrame(dataset)\n",
    "\n",
    "# ì‹¤í–‰ ë° ì €ì¥\n",
    "df = generate_hybrid_user_data_fixed(10)\n",
    "file_name = \"hybrid_user_test_data_v2.csv\"  \n",
    "df.to_csv(file_name, index=False, encoding='utf-8-sig')\n",
    "print(\"âœ… ë°ì´í„°ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ({})\".format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc713de",
   "metadata": {},
   "source": [
    "---\n",
    "### ê°€ìƒ ë°ì´í„° ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e9741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ ìˆ˜ì‹ í…ŒìŠ¤íŠ¸ìš© ë§ˆìŠ¤í„° ë°ì´í„° 1,200ê°œ ìƒì„± ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# 1. í•œê¸€ë¡œ ë°”ë€ JSON ë°ì´í„° ë¡œë“œ\n",
    "# (ì£¼ì˜: íŒŒì¼ ë‚´ team_name, style_tags ë“±ì´ í•œê¸€ë¡œ ë˜ì–´ ìˆì–´ì•¼ í•´!)\n",
    "with open('final_team_data_korean.json', 'r', encoding='utf-8') as f:\n",
    "    teams = json.load(f)\n",
    "\n",
    "def generate_korean_user_data(num=1000):\n",
    "    dataset = []\n",
    "    samples_per_team = num // len(teams)\n",
    "\n",
    "    # íƒ€ ì¢…ëª© íŒ¬ë¤ ë§¤í•‘ (ê¸°íšì•ˆì˜ 'íŒ¬ë¤ êµì°¨' ë°˜ì˜)\n",
    "    cross_sports = {\n",
    "        \"ê¸°ì•„ íƒ€ì´ê±°ì¦ˆ\": \"ì—´ì •ì ì´ê³  ì „í†µ ìˆëŠ”\",\n",
    "        \"ë§¨ì²´ìŠ¤í„° ì‹œí‹°\": \"ì••ë„ì ì´ê³  í™”ë ¤í•œ\",\n",
    "        \"í† íŠ¸ë„˜\": \"ì–¸ë”ë…ì˜ ë°˜ë€ì´ ê¸°ëŒ€ë˜ëŠ”\",\n",
    "        \"LG íŠ¸ìœˆìŠ¤\": \"íŒ¬ë“¤ì˜ ì¶©ì„±ë„ê°€ ë†’ì€\",\n",
    "        \"í•œí™” ì´ê¸€ìŠ¤\": \"ë³´ì‚´ íŒ¬ë¤ê³¼ ì„œì‚¬ê°€ ê°•ë ¥í•œ\"\n",
    "    }\n",
    "\n",
    "    for team in teams:\n",
    "        for _ in range(samples_per_team):\n",
    "            # í˜ë¥´ì†Œë‚˜ ì„ íƒ\n",
    "            dtype = random.choices([\"ì§ì„¤í˜•\", \"ì„œì‚¬í˜•\", \"íŒ¬ë¤êµì°¨í˜•\"], weights=[50, 30, 20])[0]\n",
    "            \n",
    "            if dtype == \"ì§ì„¤í˜•\":\n",
    "                # JSONì˜ í•œê¸€ íƒœê·¸ í™œìš©\n",
    "                kws = random.sample(team['style_tags'], 2)\n",
    "                query = f\"{kws[0]} ëŠë‚Œì´ë‘ {kws[1]} ë¶„ìœ„ê¸° ë‚˜ëŠ” íŒ€ ì¶”ì²œí•´ì¤˜.\"\n",
    "            \n",
    "            elif dtype == \"ì„œì‚¬í˜•\":\n",
    "                # scores ë°ì´í„°ë¥¼ ë¬¸ì¥ìœ¼ë¡œ ë…¹ì—¬ëƒ„\n",
    "                if team['scores']['underdog_feel'] > 7:\n",
    "                    query = \"ì„±ì ì€ ì¢€ ë‚®ì•„ë„ ì–¸ë”ë…ì˜ ë°˜ë€ ê°™ì€ ë“œë¼ë§ˆí‹±í•œ íŒ€ì´ ëŒë ¤ìš”.\"\n",
    "                elif team['scores']['tradition'] > 8:\n",
    "                    query = \"ì—­ì‚¬ê°€ ê¹Šê³  ì „í†µì´ ëŠê»´ì§€ëŠ” ëª…ë¬¸ íŒ€ì„ ì‘ì›í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.\"\n",
    "                else:\n",
    "                    query = \"ì§€ê¸ˆ ë‹¹ì¥ ê°€ì¥ ì‹¤ë ¥ì´ ì¢‹ê³  ìš°ìŠ¹ í™•ë¥ ì´ ë†’ì€ íŒ€ì´ ì–´ë””ì•¼?\"\n",
    "            \n",
    "            else: # íŒ¬ë¤êµì°¨í˜•\n",
    "                p_team, p_vibe = random.choice(list(cross_sports.items()))\n",
    "                query = f\"ì € {p_team} íŒ¬ì¸ë°, F1ì—ì„œë„ {p_vibe} íŒ€ì´ ìˆì„ê¹Œìš”?\"\n",
    "\n",
    "            dataset.append({\n",
    "                \"ì‚¬ìš©ì_ì§ˆë¬¸\": query,\n",
    "                \"ì •ë‹µ_íŒ€\": team['team_name'],\n",
    "                \"ë°ì´í„°_ìœ í˜•\": dtype\n",
    "            })\n",
    "            \n",
    "    return pd.DataFrame(dataset)\n",
    "\n",
    "# ë°ì´í„° ìƒì„± ë° CSV ì €ì¥\n",
    "df_korean = generate_korean_user_data(1200)\n",
    "df_korean.to_csv(\"í•œê¸€_ê°€ìƒ_ì§ˆë¬¸_ë°ì´í„°.csv\", index=False, encoding='utf-8-sig')\n",
    "print(\"âœ… í•œê¸€ ê°€ìƒ ë°ì´í„° 1,200ê°œ ìƒì„±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0b4fb",
   "metadata": {},
   "source": [
    "---\n",
    "### ì†Œìˆ˜ íŒ€ë§Œìœ¼ë¡œ ì½”ë“œ ë½‘ì•„ë´„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e3e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Project\\2025_Sports_Chatbot\\.venv\\Scripts\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "# pip install node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c97788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ\n",
    "with open('final_team_data3.json', 'r', encoding='utf-8') as f:\n",
    "    teams = json.load(f)\n",
    "\n",
    "# 2. í‚¤ì›Œë“œ-ìˆ˜ì¹˜ ì ìˆ˜ ë§¤í•‘ (ì‚¬ìš©ì ë§ì„ Scoreë¡œ ë³€í™˜í•˜ëŠ” ë‹¤ë¦¬ ì—­í• )\n",
    "score_map = {\n",
    "    \"strength\": [\"ê°•í•œ\", \"ì‹¤ë ¥ ìˆëŠ”\", \"ìš°ìŠ¹ í›„ë³´\", \"ì••ë„ì ì¸\"],\n",
    "    \"money\": [\"ìë³¸ë ¥ì´ ì¢‹ì€\", \"ëˆ ë§ì€\", \"íˆ¬ìë¥¼ ë§ì´ í•˜ëŠ”\"],\n",
    "    \"star_power\": [\"ìŠ¤íƒ€ ì„ ìˆ˜ê°€ ìˆëŠ”\", \"ìœ ëª…í•œ\", \"í™”ë ¤í•œ\"],\n",
    "    \"attack_style\": [\"ê³µê²©ì ì¸\", \"í™”ëˆí•œ\", \"ì†ë„ê° ìˆëŠ”\"],\n",
    "    \"underdog_feel\": [\"ì–¸ë”ë…\", \"ì•½íŒ€ì˜ ë°˜ë€\", \"ë„ì „í•˜ëŠ”\"],\n",
    "    \"fan_passion\": [\"íŒ¬ë¤ì´ ëœ¨ê±°ìš´\", \"ì‘ì›ì´ ì—´ì •ì ì¸\", \"ì¸ê¸° ë§ì€\"],\n",
    "    \"tradition\": [\"ì—­ì‚¬ê°€ ê¹Šì€\", \"ì „í†µ ìˆëŠ”\", \"ê·¼ë³¸ ìˆëŠ”\", \"ëª…ë¬¸\"]\n",
    "}\n",
    "\n",
    "def generate_soft_variance_data(num=1000):\n",
    "    dataset = []\n",
    "    unique_tags = list(set([tag for t in teams for tag in t['style_tags']]))\n",
    "\n",
    "    for _ in range(num):\n",
    "        # ëœë¤í•˜ê²Œ 1~2ê°œì˜ ìˆ˜ì¹˜ ì¹´í…Œê³ ë¦¬ì™€ 1ê°œì˜ íƒœê·¸ ì„ íƒ\n",
    "        selected_cats = random.sample(list(score_map.keys()), random.randint(1, 2))\n",
    "        selected_tag = random.sample(unique_tags, 1)[0]\n",
    "        \n",
    "        # ìì—°ìŠ¤ëŸ¬ìš´ í•œê¸€ ì§ˆë¬¸ ìƒì„±\n",
    "        keywords = [random.choice(score_map[cat]) for cat in selected_cats]\n",
    "        query = f\"{' ê·¸ë¦¬ê³  '.join(keywords)} ëŠë‚Œì´ ë‚˜ë©´ì„œ {selected_tag} ê°™ì€ ë©´ëª¨ë„ ìˆëŠ” íŒ€ì´ ìˆì„ê¹Œ?\"\n",
    "        \n",
    "        for team in teams:\n",
    "            # â‘  S_semantic (íƒœê·¸ ë§¤ì¹˜ - ë¹„ì¤‘ ë‚®ì¶¤): 0.4 ê°€ì¤‘ì¹˜\n",
    "            tag_match = 1.0 if selected_tag in team['style_tags'] else 0.2\n",
    "            \n",
    "            # â‘¡ S_relational (ìˆ˜ì¹˜ ì ìˆ˜ ë§¤ì¹˜ - ë¹„ì¤‘ ë†’ì„): 0.6 ê°€ì¤‘ì¹˜\n",
    "            # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ë“¤ì˜ ì ìˆ˜ í‰ê· ì„ ë‚´ì„œ ë°˜ì˜\n",
    "            vibe_scores = [team['scores'][cat] / 10.0 for cat in selected_cats]\n",
    "            s_relational = np.mean(vibe_scores)\n",
    "            \n",
    "            # â‘¢ W_id (ê°€ì¤‘ì¹˜ í•„í„°)\n",
    "            w_id = 0.9 + (team['scores']['underdog_feel'] / 100) + (team['scores']['tradition'] / 100)\n",
    "            \n",
    "            # ìµœì¢… ì ìˆ˜ ê³„ì‚°: (íƒœê·¸*0.4 + ìˆ˜ì¹˜*0.6) * ê°€ì¤‘ì¹˜\n",
    "            final_score = (0.4 * tag_match + 0.6 * s_relational) * w_id\n",
    "            \n",
    "            dataset.append({\n",
    "                \"user_query\": query,\n",
    "                \"team_name\": team['team_name'],\n",
    "                \"label_score\": round(min(0.98, final_score), 4),\n",
    "                \"focused_scores\": \", \".join(selected_cats)\n",
    "            })\n",
    "            \n",
    "    return pd.DataFrame(dataset)\n",
    "\n",
    "# ì‹¤í–‰ ë° ì €ì¥\n",
    "df_nuanced = generate_soft_variance_data(300) # 300ë²ˆ ë°˜ë³µ (íŒ€ë‹¹ 300ê°œ ì§ˆë¬¸)\n",
    "df_nuanced.to_csv(\"nuanced_score_data.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39871d",
   "metadata": {},
   "source": [
    "---\n",
    "í¬ê´„ì ì¸ ì§ˆë¬¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52fcc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# 1. í…ŒìŠ¤íŠ¸í•  í¬ê´„ì  í‚¤ì›Œë“œ ('ìŠ¤ì½”ì–´'ì™€ ì—°ê²°ë  í•­ëª©ë“¤)\n",
    "#\n",
    "concept_pool = {\n",
    "    \"ê³µê²©ì„±\": [\"í™”ëˆí•˜ê²Œ ê³µê²©í•˜ëŠ”\", \"ì¶”ì›”ì„ ë¬´ì„œì›Œí•˜ì§€ ì•ŠëŠ”\", \"ê³µê²©ì ì¸ ë“œë¼ì´ë¹™\", \"ê³µê²© ìœ„ì£¼ì˜\"],\n",
    "    \"ìë³¸/ì¬ë ¥\": [\"ëˆì´ ë§ì€\", \"íˆ¬ìë¥¼ ì•„ë¼ì§€ ì•ŠëŠ”\", \"ìë³¸ë ¥ì´ ë¹µë¹µí•œ\", \"ë¶€ìœ í•œ êµ¬ë‹¨\"],\n",
    "    \"ì „í†µ/ì—­ì‚¬\": [\"ê·¼ë³¸ ìˆëŠ”\", \"ì—­ì‚¬ê°€ ê¹Šì€\", \"ëª…ë¬¸ íŒ€\", \"ì „í†µì„ ì†Œì¤‘íˆ í•˜ëŠ”\"],\n",
    "    \"ìŠ¤íƒ€ì„±\": [\"ìœ ëª…í•œ ë“œë¼ì´ë²„ê°€ ìˆëŠ”\", \"ìŠˆí¼ìŠ¤íƒ€ê°€ ìˆëŠ”\", \"í™”ë ¤í•œ ì¸ì§€ë„ì˜\"],\n",
    "    \"ì–¸ë”ë…/ì„œì‚¬\": [\"ê¼´ì°Œì˜ ë°˜ë€\", \"ë„ì „í•˜ëŠ” ì •ì‹ \", \"ì•½íŒ€ì´ì§€ë§Œ ì €ë ¥ ìˆëŠ”\", \"ìŠ¤í† ë¦¬ê°€ ìˆëŠ”\"]\n",
    "}\n",
    "\n",
    "def generate_broad_test_queries(target_team_name=\"ë§¥ë¼ë Œ\", num=30):\n",
    "    dataset = []\n",
    "    \n",
    "    # 'ì§ˆë¬¸ì˜ êµ¬ì²´ì„±'ì— ë”°ë¥¸ ì ìˆ˜ ë³€í™”\n",
    "    for _ in range(num):\n",
    "        # 1. í¬ê´„ì ì¸ ì»¨ì…‰ í•˜ë‚˜ ì„ íƒ\n",
    "        category = random.choice(list(concept_pool.keys()))\n",
    "        vibe = random.choice(concept_pool[category])\n",
    "        \n",
    "        # 2. ì§ˆë¬¸ ìƒì„± (íƒœê·¸ë¥¼ ì§ì ‘ ì•ˆ ì“°ê³  'ëŠë‚Œ'ìœ¼ë¡œ ë¬¼ì–´ë´„)\n",
    "        #\n",
    "        templates = [\n",
    "            f\"ì €ëŠ” ì¢€ {vibe} íŒ€ì„ ì‘ì›í•˜ê³  ì‹¶ì–´ìš”. ì–´ë””ê°€ ì¢‹ì„ê¹Œìš”?\",\n",
    "            f\"F1 íŒ€ ì¤‘ì—ì„œ {vibe} ëŠë‚Œì´ ê°•í•œ ê³³ ì¶”ì²œ ë¶€íƒë“œë ¤ìš”.\",\n",
    "            f\"{vibe} ë§¤ë ¥ì´ ìˆëŠ” íŒ€ì´ ë‚˜ë‘ ì˜ ë§ì„ ê²ƒ ê°™ì•„ìš”.\",\n",
    "            f\"ì„±ì ë„ ì¤‘ìš”í•˜ì§€ë§Œ {vibe} ìŠ¤í† ë¦¬ê°€ ìˆëŠ” íŒ€ì´ ëŒë¦¬ë„¤ìš”.\"\n",
    "        ]\n",
    "        query = random.choice(templates)\n",
    "        \n",
    "        # 3. ê²°ê³¼ ê¸°ë¡\n",
    "        dataset.append({\n",
    "            \"í…ŒìŠ¤íŠ¸_ì¹´í…Œê³ ë¦¬\": category,\n",
    "            \"ì‚¬ìš©ì_ì§ˆë¬¸\": query,\n",
    "            \"íƒ€ê²Ÿ_íŒ€\": target_team_name\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(dataset)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "df_test = generate_broad_test_queries(\"ë§¥ë¼ë Œ\", 50)\n",
    "df_test.to_csv(\"í…ŒìŠ¤íŠ¸_ì§ˆë¬¸.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
